# Phase 12 Implementation Plan: Complete GPU Optimization

## Date
2025-10-23

## Status
ðŸ“‹ **IMPLEMENTATION PLAN** - Ready for execution

---

## Executive Summary

Based on Phase 11's confirmed GPU stall diagnosis, this document provides a detailed implementation plan for the three critical optimizations that will eliminate 80-95% of GPU stalls and achieve smooth 60+ FPS during resize.

---

## Priority 1: Buffer Pooling Integration â­â­â­â­â­

### Current State

**File**: `wezterm-gui/src/renderstate.rs`

**Current flow** (lines 503-554):
```rust
pub fn reallocate_quads(&self, idx: usize, num_quads: usize) -> anyhow::Result<()> {
    let vb = Self::compute_vertices(&self.context, num_quads)?;  // Allocates fresh!
    self.vb.borrow_mut()[idx] = vb;
    Ok(())
}

fn compute_vertices(context: &RenderContext, num_quads: usize) -> anyhow::Result<TripleVertexBuffer> {
    // Allocates 3 new vertex buffers every time!
    let buffer = TripleVertexBuffer {
        bufs: RefCell::new([
            context.allocate_vertex_buffer(num_quads, &verts)?,  // GPU ALLOCATION!
            context.allocate_vertex_buffer(num_quads, &verts)?,  // GPU ALLOCATION!
            context.allocate_vertex_buffer(num_quads, &verts)?,  // GPU ALLOCATION!
        ]),
        capacity: num_quads,
        // ...
    };
    Ok(buffer)
}
```

**Problem**: Each resize allocates 3 fresh buffers â†’ 100-200ms GPU stall!

### Proposed Changes

#### Step 1: Modify `RenderLayer` to hold buffer pool reference

**Add to `RenderLayer` struct** (line 454):
```rust
pub struct RenderLayer {
    pub vb: RefCell<[TripleVertexBuffer; 3]>,
    context: RenderContext,
    zindex: i8,
    buffer_pool: Rc<VertexBufferPool>,  // NEW!
}
```

**Update constructor** (line 461):
```rust
pub fn new(
    context: &RenderContext,
    buffer_pool: &Rc<VertexBufferPool>,  // NEW PARAMETER!
    num_quads: usize,
    zindex: i8
) -> anyhow::Result<Self> {
    let vb = [
        Self::compute_vertices(context, buffer_pool, 32)?,
        Self::compute_vertices(context, buffer_pool, num_quads)?,
        Self::compute_vertices(context, buffer_pool, 32)?,
    ];

    Ok(Self {
        context: context.clone(),
        vb: RefCell::new(vb),
        zindex,
        buffer_pool: Rc::clone(buffer_pool),  // NEW!
    })
}
```

#### Step 2: Modify `compute_vertices` to use buffer pool

**New signature and implementation**:
```rust
fn compute_vertices(
    context: &RenderContext,
    buffer_pool: &Rc<VertexBufferPool>,
    num_quads: usize,
) -> anyhow::Result<TripleVertexBuffer> {
    let verts = context.allocate_vertex_buffer_initializer(num_quads);
    log::debug!(
        "compute_vertices num_quads={}, attempting to use buffer pool",
        num_quads
    );
    
    let mut indices = vec![];
    indices.reserve(num_quads * INDICES_PER_CELL);

    for q in 0..num_quads {
        let idx = (q * VERTICES_PER_CELL) as u32;
        indices.push(idx + V_TOP_LEFT as u32);
        indices.push(idx + V_TOP_RIGHT as u32);
        indices.push(idx + V_BOT_LEFT as u32);
        indices.push(idx + V_TOP_RIGHT as u32);
        indices.push(idx + V_BOT_LEFT as u32);
        indices.push(idx + V_BOT_RIGHT as u32);
    }

    // Try to acquire buffers from pool
    let (cap1, buf1) = buffer_pool.acquire(num_quads)?;
    let (cap2, buf2) = buffer_pool.acquire(num_quads)?;
    let (cap3, buf3) = buffer_pool.acquire(num_quads)?;
    
    log::debug!(
        "Acquired buffers: cap1={}, cap2={}, cap3={} for num_quads={}",
        cap1, cap2, cap3, num_quads
    );

    let buffer = TripleVertexBuffer {
        index: RefCell::new(0),
        bufs: RefCell::new([buf1, buf2, buf3]),
        capacity: num_quads,
        indices: context.allocate_index_buffer(&indices)?,
        next_quad: RefCell::new(0),
    };

    Ok(buffer)
}
```

#### Step 3: Add buffer release in `reallocate_quads`

**Modified implementation**:
```rust
pub fn reallocate_quads(&self, idx: usize, num_quads: usize) -> anyhow::Result<()> {
    // Release old buffers back to pool before allocating new ones
    {
        let old_vb = &self.vb.borrow()[idx];
        let old_bufs = old_vb.bufs.borrow();
        for buf in old_bufs.iter() {
            self.buffer_pool.release(old_vb.capacity, buf.clone());
        }
        log::debug!(
            "Released {} buffers with capacity {} back to pool",
            old_bufs.len(),
            old_vb.capacity
        );
    }
    
    // Allocate new buffers from pool
    let vb = Self::compute_vertices(&self.context, &self.buffer_pool, num_quads)?;
    self.vb.borrow_mut()[idx] = vb;
    
    log::info!(
        "Reallocated quads for layer {} index {}: {} quads (pool stats: {:?})",
        self.zindex,
        idx,
        num_quads,
        self.buffer_pool.stats()
    );
    
    Ok(())
}
```

#### Step 4: Update all `RenderLayer::new()` call sites

**In `RenderState::new()`** (line 602):
```rust
let main_layer = Rc::new(RenderLayer::new(
    &context,
    &buffer_pool,  // NEW!
    1024,
    0
)?);
```

**In `RenderState::layer_for_zindex()`** (line 635):
```rust
let layer = Rc::new(RenderLayer::new(
    &self.context,
    &self.buffer_pool,  // NEW!
    128,
    zindex
)?);
```

### Expected Impact

**Before**:
- Each `reallocate_quads()`: 3 GPU allocations = 100-200ms
- 70+ calls during resize = 7-14 seconds wasted

**After**:
- First call: 3 GPU allocations = 100-200ms (one-time)
- Subsequent calls: 3 pool lookups = <0.1ms each
- 70+ calls during resize = ~7ms total!

**Improvement**: **1000x faster!** (7ms vs 7000ms)

---

## Priority 2: Deferred Texture Atlas Growth â­â­â­â­â­

### Current State

**File**: `wezterm-gui/src/termwindow/render/paint.rs`

**Current flow** (lines 63-105):
```rust
'pass: for pass in 0.. {
    match self.paint_pass() {
        Ok(_) => match self.render_state.allocated_more_quads() {
            Ok(allocated) => {
                if !allocated { break 'pass; }
                // Retry with more quads
            }
        },
        Err(err) => {
            if let Some(&OutOfTextureSpace) = err.downcast_ref() {
                // BLOCKS CURRENT FRAME!
                self.recreate_texture_atlas(Some(size * 2));  // 600-750ms!
            }
        }
    }
}
```

**Problem**: Texture atlas growth blocks current frame for 600-750ms!

### Proposed Changes

#### Step 1: Add pending texture growth field

**In `TermWindow` struct** (`wezterm-gui/src/termwindow/mod.rs`):
```rust
pub struct TermWindow {
    // ... existing fields ...
    
    // Deferred texture atlas growth
    pending_texture_growth: Option<usize>,
    texture_growth_deferred_count: usize,
}
```

**Initialize in constructor**:
```rust
pending_texture_growth: None,
texture_growth_deferred_count: 0,
```

#### Step 2: Queue texture growth instead of blocking

**Modify paint_impl**:
```rust
'pass: for pass in 0.. {
    match self.paint_pass() {
        Ok(_) => match self.render_state.allocated_more_quads() {
            Ok(allocated) => {
                if !allocated { break 'pass; }
            }
        },
        Err(err) => {
            if let Some(&OutOfTextureSpace { size: Some(new_size), .. }) = err.downcast_ref() {
                // DON'T BLOCK! Queue for next frame instead
                if self.pending_texture_growth.is_none() {
                    self.pending_texture_growth = Some(new_size * 2);
                    self.texture_growth_deferred_count += 1;
                    
                    log::warn!(
                        "Texture atlas out of space (need {}). Deferring growth to next frame (deferred {} times).",
                        new_size * 2,
                        self.texture_growth_deferred_count
                    );
                    
                    // Use current atlas with reduced quality for this frame
                    // This is OK - we'll have proper textures next frame
                    break 'pass;
                }
            } else if let Some(&OutOfTextureSpace { size: None, .. }) = err.downcast_ref() {
                anyhow::bail!("requested texture size is impossible!?")
            } else {
                // Other error types
                log::error!("paint_pass failed: {:#}", err);
                break 'pass;
            }
        }
    }
}
```

#### Step 3: Apply texture growth at frame start

**Add to start of `paint_impl`**:
```rust
pub fn paint_impl(&mut self, frame: &mut RenderFrame) {
    // Apply any pending texture atlas growth from previous frame
    if let Some(new_size) = self.pending_texture_growth.take() {
        let start = Instant::now();
        
        log::info!(
            "Applying deferred texture atlas growth to {} (deferred {} times)",
            new_size,
            self.texture_growth_deferred_count
        );
        
        match self.recreate_texture_atlas(Some(new_size)) {
            Ok(_) => {
                let elapsed = start.elapsed();
                log::info!(
                    "Texture atlas growth completed in {:?}",
                    elapsed
                );
            }
            Err(e) => {
                log::error!(
                    "Failed to grow texture atlas: {:#}. Will retry.",
                    e
                );
                // Re-queue for next frame
                self.pending_texture_growth = Some(new_size);
            }
        }
    }
    
    // ... rest of paint_impl ...
}
```

### Expected Impact

**Before**:
- Texture growth during frame: 600-750ms (BLOCKS!)
- Worst-case frame time: 750ms

**After**:
- Texture growth queued: < 0.1ms (no block!)
- Growth applied next frame start: 600-750ms (but not blocking user!)
- Worst-case frame time: 100-200ms (vertex buffers only)

**Improvement**: **5-7x better worst-case performance!**

---

## Priority 3: Explicit GPU Fence Sync â­â­â­â­

### Current State

**Implicit synchronization**: CPU blocks indefinitely waiting for GPU

**Problem**: No timeout, no diagnostics, no graceful handling

### Proposed Changes

#### Step 1: Add EGL fence sync module

**New file**: `window/src/os/wayland/egl_fence.rs`

```rust
use anyhow::{anyhow, Result};
use std::time::{Duration, Instant};

/// EGL sync fence for explicit GPU synchronization
pub struct EglFence {
    // Platform-specific sync object
    // For now, we'll use a simpler approach via glFinish with timeout simulation
}

impl EglFence {
    /// Create a new sync fence
    pub fn new() -> Result<Self> {
        // TODO: Use proper EGL sync objects when available
        // eglCreateSyncKHR(display, EGL_SYNC_FENCE_KHR, NULL)
        Ok(Self {})
    }
    
    /// Wait for fence with timeout
    /// Returns true if signaled, false if timeout
    pub fn wait_with_timeout(&self, timeout: Duration) -> Result<bool> {
        let start = Instant::now();
        
        // TODO: Use proper EGL client wait
        // eglClientWaitSyncKHR(display, sync, EGL_SYNC_FLUSH_COMMANDS_BIT_KHR, timeout_ns)
        
        // For now, we can't actually implement this without EGL context
        // But we can add the infrastructure
        
        let elapsed = start.elapsed();
        
        if elapsed > timeout {
            log::warn!(
                "GPU fence wait timeout after {:?} (requested {:?})",
                elapsed,
                timeout
            );
            return Ok(false);
        }
        
        Ok(true)
    }
}
```

#### Step 2: Integrate fence sync in Wayland window

**Modify `do_paint()` in `window/src/os/wayland/window.rs`**:

```rust
fn do_paint(&mut self) -> anyhow::Result<()> {
    // ... existing code ...
    
    // Track when we started waiting for this frame callback
    self.frame_callback_start = Some(Instant::now());
    
    // Check if we should warn about potential GPU stall
    // This helps detect when we're about to enter a long wait
    if let Some(gl_state) = &self.gl_state {
        // In a real implementation, we'd create an EGL fence here
        // and check it periodically to detect stalls earlier
        
        log::trace!("Frame callback requested, monitoring for GPU stalls");
    }
    
    self.frame_callback.replace(callback);
    
    // ... rest of code ...
}
```

**Enhanced stall detection in frame callback wait**:

```rust
if self.frame_callback.is_some() {
    // GPU stall detection: Check how long we've been waiting
    if let Some(start) = self.frame_callback_start {
        let wait_time = Instant::now().duration_since(start);
        
        // Progressive warnings
        if wait_time > Duration::from_millis(500) {
            let since_last_warning = Instant::now().duration_since(self.last_gpu_stall_warning);
            
            if since_last_warning > Duration::from_secs(1) {
                self.gpu_stall_count += 1;
                log::error!(
                    "SEVERE GPU stall: waiting {:?} for frame callback (stall #{})! \
                    GPU may be hung or driver issue. Consider reporting this.",
                    wait_time,
                    self.gpu_stall_count
                );
                self.last_gpu_stall_warning = Instant::now();
            }
        } else if wait_time > Duration::from_millis(200) {
            let since_last_warning = Instant::now().duration_since(self.last_gpu_stall_warning);
            
            if since_last_warning > Duration::from_secs(2) {
                self.gpu_stall_count += 1;
                log::warn!(
                    "Significant GPU stall: waiting {:?} for frame callback (stall #{})! \
                    This may indicate GPU driver issues or slow GPU operations.",
                    wait_time,
                    self.gpu_stall_count
                );
                self.last_gpu_stall_warning = Instant::now();
            }
        } else if wait_time > Duration::from_millis(100) {
            // Already logged at INFO level
        }
    }
    
    self.invalidated = true;
    return Ok(());
}
```

### Expected Impact

**Before**:
- Silent GPU stalls
- No timeout handling
- No degradation strategy

**After**:
- Progressive warnings (100ms, 200ms, 500ms)
- Clear user feedback
- Foundation for future timeout handling

**Improvement**: **Better diagnostics and user experience**

---

## Implementation Order

### Week 1: Buffer Pooling

**Day 1-2**: Buffer pool integration
- Modify `RenderLayer` to use buffer pool
- Update `compute_vertices` to acquire/release buffers
- Test with simple scenarios

**Day 3**: Buffer pool testing
- Test during resize
- Measure stall reduction
- Verify no memory leaks

**Expected result**: **80% reduction in GPU stalls!**

### Week 2: Deferred Texture Growth

**Day 4-5**: Deferred texture implementation
- Add pending texture growth field
- Queue instead of blocking
- Apply at frame start

**Day 6**: Texture growth testing
- Test with many tabs/large terminal
- Verify no visual artifacts
- Measure worst-case improvement

**Expected result**: **5x reduction in worst-case stalls!**

### Week 3: GPU Fence Sync

**Day 7**: Enhanced diagnostics
- Add progressive warnings
- Better error messages
- User-friendly feedback

**Day 8**: Testing and polish
- Full integration testing
- Performance validation
- Documentation

**Expected result**: **Better user experience!**

---

## Testing Plan

### Unit Tests

**Buffer pooling**:
```rust
#[test]
fn test_buffer_pool_reuse() {
    // Acquire buffer
    // Release buffer
    // Acquire again - should reuse
    // Verify allocation count = 1, reuse count = 1
}
```

**Texture growth**:
```rust
#[test]
fn test_deferred_texture_growth() {
    // Fill texture atlas
    // Trigger out of space
    // Verify pending_texture_growth is set
    // Verify current frame completes
    // Next frame: verify growth applied
}
```

### Integration Tests

**Resize test**:
1. Open WezTerm with 20 tabs
2. Resize window rapidly for 30 seconds
3. Measure:
   - GPU stall count
   - Average stall duration
   - Frame time variance
   - Buffer pool statistics

**Expected results**:
```
Before: 70+ stalls, avg 400ms, max 750ms
After:  70+ stalls, avg 20ms, max 100ms
```

### Performance Validation

**Collect metrics**:
- Buffer pool stats (allocations vs reuses)
- Texture growth events (count, duration)
- GPU stall frequency and duration
- Frame time distribution

**Success criteria**:
- âœ… Buffer reuse rate > 95%
- âœ… Average GPU stall < 30ms
- âœ… Max GPU stall < 150ms
- âœ… Smooth 60+ FPS during resize

---

## Expected Final Results

### Performance Improvements

| Metric | Before | After | Improvement |
|--------|--------|-------|-------------|
| **Avg GPU stall** | 400ms | 20ms | **20x better** |
| **Max GPU stall** | 750ms | 100ms | **7.5x better** |
| **Buffer allocations** | 210/resize | 3/session | **70x fewer** |
| **Texture blocks** | 10-20/resize | 0 (deferred) | **Eliminated** |
| **Resize efficiency** | 1.6% | 25% | **15x better** |

### User Experience

**Before**:
- Sluggish, janky resize
- Frequent pauses
- Frustrating experience

**After**:
- Smooth 60+ FPS
- No perceptible stalls
- Excellent experience

---

## Risk Mitigation

### Potential Issues

1. **Buffer pool memory usage**
   - Risk: Holding too many buffers
   - Mitigation: Max 8 buffers, largest 2MB each = 16MB max

2. **Texture growth artifacts**
   - Risk: Missing glyphs for one frame
   - Mitigation: Acceptable tradeoff vs 750ms stall

3. **EGL fence complexity**
   - Risk: Platform-specific issues
   - Mitigation: Start with diagnostics only, full sync later

### Rollback Plan

Each priority is independent:
- Can disable buffer pooling via flag
- Can revert to synchronous texture growth
- Can remove enhanced diagnostics

---

## Success Metrics

### Quantitative

- âœ… **20x reduction** in average GPU stall time
- âœ… **7x reduction** in worst-case GPU stall time
- âœ… **95%+ buffer reuse** rate
- âœ… **Zero texture growth blocks** during frames

### Qualitative

- âœ… Users report smooth resize
- âœ… No complaints about janky behavior
- âœ… Positive feedback on responsiveness

---

## Conclusion

This implementation plan provides a clear path to eliminate 80-95% of GPU stalls and achieve smooth 60+ FPS during window resize. The changes are well-scoped, testable, and can be implemented incrementally with low risk.

**Estimated effort**: 3 weeks  
**Expected impact**: **15-20x improvement in responsiveness**  
**Status**: Ready for implementation! ðŸš€

